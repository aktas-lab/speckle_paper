{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240ab2fb-b383-4db3-b40d-e76eda2556e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilik/anaconda33/envs/bioframe/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 9.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "import umap.plot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b30721a-32da-4a3e-bb44-c07901c97db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.5.3\n",
      "numpy version: 1.23.5\n",
      "seaborn version: 0.13.1\n",
      "umap version: 0.5.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"pandas version: {pd.__version__}\n",
    "numpy version: {np.__version__}\n",
    "seaborn version: {sns.__version__}\n",
    "umap version: {umap.__version__}\n",
    "\"\"\".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48298056-1ab3-454e-bd81-989811253118",
   "metadata": {},
   "source": [
    "When we were exploring the splicing defects in Speckle-depleted or Speckle-disturbed cells, we noticed that a very specific subset of introns were effect: GC-rich short introns surrounding GC-rich exons. When we plot these introns on a scatterplot where the x-axis represents log-transformed length of the introns and the y-axis representing GC-content, these introns would occupy the top left corner. In contrast, depleting TRA2A/B affects introns that long and GC-poor. Overall it seems like human introns explore a large GC-intron length space, but also with clear restrictions: there are few/no GC-rich introns that are also long.\n",
    "\n",
    "Simply looking at the log(length) vs GC plots of well-studied model systems is enough to see that this intron organisation is not universal. We wondered whether we can summarise this obsvervation for all the organisms that have a genome annotation at NCBI. In this notebook we try to do this by converting theses plots into 30x30 2D dataframes where each bin represents the frequency of introns in a given bin (e.g. 50-53% GC, 1-2kb). These dataframes are then used to construct a UMAP which can place similar-looking matrices with each other. The goal is to see if there are general trends that make sense with taxonomic information or not. The null hypothesis is that introns are more or less evolving freely and these distributions do not fit into clear patterns.\n",
    "\n",
    "To to this:\n",
    "\n",
    "Run the scripts that download all genome fasta files and gene annotations. These scripts also create csv files which contain all non-redundant introns and exons of protein-coding genes, abd their coordinates which are used to calculate GC content. [Pre-computed files available here: ]\n",
    "Load these files to create the 2D matrices (or plots). [Pre-computed matrices here:]\n",
    "Create the UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf34627-ba55-4a7e-bfac-7778db456e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running eveything from scratch, this is the folder that contains necessary \n",
    "# dataframes from each species\n",
    "# Can be generated by running the scripts {}\n",
    "\n",
    "DATA_FRAMES_FOLDER = \"/project/bigdata_aktas/genomes/ncbi_gc/data_frames\" \n",
    "\n",
    "def process_files(genome_dataframe, DATA_FRAMES_FOLDER, bins=30):\n",
    "    plt.ioff() # do not print the plot to console\n",
    "    \n",
    "    taxid_2D_values = dict()\n",
    "    \n",
    "    for index, row in genome_dataframe.iterrows():\n",
    "        parameters = (row['#assembly_accession'], \n",
    "              '_'.join(row['organism_name'].split()), \n",
    "              row['group'], \n",
    "             row['ftp_path'],\n",
    "            row['taxid'])\n",
    "        \n",
    "        assembly_name, organism_name, group, ftp_path, taxid = parameters\n",
    "\n",
    "        intron_out = f\"{DATA_FRAMES_FOLDER}/{group}/introns/{organism_name}_{assembly_name}_introns.csv.gz\"\n",
    "        if os.path.isfile(intron_out):\n",
    "            introns_bf = pd.read_csv(intron_out)\n",
    "            introns_bf['intron_length_log'] = np.log10(introns_bf.intron_length)\n",
    "            \n",
    "            values = plt.hist2d(introns_bf.intron_length_log, \n",
    "                                introns_bf.GC, \n",
    "                                density=False,\n",
    "                                range=[[1,6],[0,1]],\n",
    "                                bins=bins)\n",
    "            plt.close()\n",
    "            \n",
    "            taxid_2D_values[taxid] = values[0].flatten()\n",
    "        else:\n",
    "            print(f'Skipping:\\t{group}, {organism_name}, intron output missing')\n",
    "    return taxid_2D_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52f6c0b-f2e7-4ef6-8b4f-ff77ecf62f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_genome_dataframes(use_archived=True):\n",
    "    vertebrate_mammalian_path = Path(\"data/pre-processed/vertebrate_mammalian.csv.gz\")\n",
    "    vertebrate_other_path = Path(\"vertebrate_other.csv.gz\")\n",
    "    invertebrate_path = Path(\"invertebrate.csv.gz\")\n",
    "    plant_path = Path(\"plant.csv.gz\")\n",
    "    fungi_path = Path(\"fungi.csv.gz\")\n",
    "\n",
    "    paths_exist = (vertebrate_mammalian_path.exists() \n",
    "                   and vertebrate_other_path.exists() \n",
    "                   and invertebrate_path.exists() \n",
    "                   and plant_path.exists() \n",
    "                   and fungi_path.exists()\n",
    "                  )\n",
    "\n",
    "    if use_archived and paths_exist:\n",
    "        vertebrate_mammalian = pd.read_csv(\"/project/bigdata_aktas/genomes/ncbi_gc/genomes_info_archive/2025-10-01/vertebrate_mammalian.csv.gz\")\n",
    "        vertebrate_other = pd.read_csv(\"/project/bigdata_aktas/genomes/ncbi_gc/genomes_info_archive/2025-10-01/vertebrate_other.csv.gz\")\n",
    "        invertebrate = pd.read_csv(\"/project/bigdata_aktas/genomes/ncbi_gc/genomes_info_archive/2025-10-01/invertebrate.csv.gz\")\n",
    "        plant = pd.read_csv(\"/project/bigdata_aktas/genomes/ncbi_gc/genomes_info_archive/2025-10-01/plant.csv.gz\")\n",
    "        fungi = pd.read_csv(\"/project/bigdata_aktas/genomes/ncbi_gc/genomes_info_archive/2025-10-01/fungi.csv.gz\")\n",
    "    \n",
    "    else: #directly loaded from NCBI\n",
    "        vertebrate_mammalian_direct = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/vertebrate_mammalian/assembly_summary.txt\"\n",
    "        vertebrate_other_direct = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/vertebrate_other/assembly_summary.txt\"\n",
    "        invertebrate_direct = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/invertebrate/assembly_summary.txt\"\n",
    "        plant_direct = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/plant/assembly_summary.txt\"\n",
    "        fungi_direct = \"https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/assembly_summary.txt\"\n",
    "        \n",
    "        vertebrate_mammalian = pd.read_csv(vertebrate_mammalian_direct, sep=\"\\t\", skiprows=1)\n",
    "        vertebrate_other = pd.read_csv(vertebrate_other_direct, sep=\"\\t\", skiprows=1)\n",
    "        invertebrate = pd.read_csv(invertebrate_direct, sep=\"\\t\", skiprows=1)\n",
    "        plant = pd.read_csv(plant_direct, sep=\"\\t\", skiprows=1)\n",
    "        fungi = pd.read_csv(fungi_direct, sep=\"\\t\", skiprows=1)\n",
    "        \n",
    "    vertebrate_mammalian['group'] = 'vertebrate_mammalian'\n",
    "    vertebrate_other['group'] = 'vertebrate_other'\n",
    "    invertebrate['group'] = 'invertebrate'\n",
    "    plant['group'] = 'plant'\n",
    "    fungi['group'] = 'fungi'\n",
    "    \n",
    "    taxid_organism_name = pd.concat([vertebrate_mammalian[['taxid', 'organism_name', '#assembly_accession', 'group']], \n",
    "               vertebrate_other[['taxid', 'organism_name', '#assembly_accession', 'group']],\n",
    "               invertebrate[['taxid', 'organism_name', '#assembly_accession', 'group']],\n",
    "               plant[['taxid', 'organism_name', '#assembly_accession', 'group']],\n",
    "               fungi[['taxid', 'organism_name', '#assembly_accession', 'group']]\n",
    "              ]\n",
    "             ).drop_duplicates('taxid')\n",
    "    \n",
    "    taxid_organism_name\n",
    "\n",
    "    return vertebrate_mammalian, vertebrate_other, invertebrate, plant, fungi, taxid_organism_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56ce0d5-e1a1-4035-873b-52386075aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_taxid_2D_merged():\n",
    "    vertebrate_mammalian, vertebrate_other, invertebrate, plant, fungi, taxid_organism_name = generate_genome_dataframes()\n",
    "    \n",
    "    taxid_2D_values_mammalian = process_files(vertebrate_mammalian.drop_duplicates('taxid'), bins=30)\n",
    "    taxid_2D_values_vertebrate = process_files(vertebrate_other.drop_duplicates('taxid'), bins=30)\n",
    "    taxid_2D_values_invertebrate = process_files(invertebrate.drop_duplicates('taxid'), bins=30)\n",
    "    taxid_2D_values_plant = process_files(plant.drop_duplicates('taxid'), bins=30)\n",
    "    taxid_2D_values_fungi = process_files(fungi.drop_duplicates('taxid'), bins=30)\n",
    "    \n",
    "    taxid_2D_values_mammalian_df = pd.DataFrame.from_dict(taxid_2D_values_mammalian).T\n",
    "    taxid_2D_values_vertebrate_df = pd.DataFrame.from_dict(taxid_2D_values_vertebrate).T\n",
    "    taxid_2D_values_invertebrate_df = pd.DataFrame.from_dict(taxid_2D_values_invertebrate).T\n",
    "    taxid_2D_values_plant_df = pd.DataFrame.from_dict(taxid_2D_values_plant).T\n",
    "    taxid_2D_values_fungi_df = pd.DataFrame.from_dict(taxid_2D_values_fungi).T\n",
    "    \n",
    "    taxid_2D_merged = pd.concat([taxid_2D_values_mammalian_df,\n",
    "                                 taxid_2D_values_vertebrate_df, \n",
    "                                taxid_2D_values_invertebrate_df,\n",
    "                                taxid_2D_values_plant_df,\n",
    "                                taxid_2D_values_fungi_df])\n",
    "    return taxid_2D_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f3f76d-e4b2-4219-b9b5-15f459b416fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reproduce the UMAP in the manuscript, load the pre-calculated matrix\n",
    "# To run it from scratch set the path below to nothing\n",
    "\n",
    "PATH_TO_taxid_2D_merged_pickle = Path(\"data/pre-processed/taxid_2D_merged.pkl.gz\", compression='gzip')\n",
    "\n",
    "if PATH_TO_taxid_2D_merged_pickle.exists():\n",
    "    taxid_2D_merged = pd.read_pickle(PATH_TO_taxid_2D_merged_pickle)\n",
    "else:\n",
    "    taxid_2D_merged = generate_taxid_2D_merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c87b31-9f18-424f-b51d-b9b82f4ea313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm removing salmonids, they have a very unique intron distribution\n",
    "# which creates a tiny island of it's own away from everybody else, squishing the rest of the UMAP\n",
    "# skip this cell to create UMAP with salmonids\n",
    "\n",
    "salmonids = \"\"\"74940\n",
    "8017\n",
    "8022\n",
    "90313\n",
    "8032\n",
    "8019\n",
    "8038\n",
    "59861\n",
    "2691554\n",
    "8023\n",
    "8030\n",
    "8040\n",
    "8018\"\"\".split()\n",
    "\n",
    "salmonids = [int(x) for x in salmonids]\n",
    "\n",
    "taxid_2D_merged = taxid_2D_merged[~taxid_2D_merged.index.isin(salmonids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9871e84-1a9c-4924-8e8d-1adbea2acc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices contain raw counts, we normalize these values with the min_max_scaler function so all values are between 0-1\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "taxid_2D_merged_min_max_scaled = min_max_scaler.fit_transform(taxid_2D_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b5776-3869-474a-8d0f-bfa83926702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilik/anaconda33/envs/bioframe/lib/python3.9/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "# Generate the embedding for UMAP\n",
    "taxid_2D_merged_min_max_scaled_embedding = umap.UMAP(min_dist=0.1, \n",
    "                                             n_neighbors=15, \n",
    "                                             random_state=42).fit(taxid_2D_merged_min_max_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e7929-da8a-47ef-897b-41cd8877838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load taxonomy info, generated with ETE3\n",
    "PATH_TO_TAX = Path(\"data/pre-processed/taxonomy_info.csv.gz\")\n",
    "taxonomy_info = pd.read_csv(PATH_TO_TAX)\n",
    "\n",
    "# Comment this if salmonids are included above\n",
    "taxonomy_info = taxonomy_info[~(taxonomy_info.taxid.isin(salmonids))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7b891-1595-458e-8661-3999ec5a01e0",
   "metadata": {},
   "source": [
    "## Figure 6D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e3943-fca9-4c19-a3e2-ad9acee9e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "color_dict={\n",
    "    \"Mammals\":\"red\",\n",
    "    \"Mice\":\"pink\",\n",
    "    \"Birds\":\"blue\",\n",
    "    \"Turtles\":\"gold\",\n",
    "    \"Alligators & Crocs\":\"orange\",\n",
    "    \"Lizards & Snakes\":\"hotpink\",\n",
    "    \"Amphibians\":\"dodgerblue\",\n",
    "    \"Fish\":\"teal\",\n",
    "    \"Invertebrates\":\"black\",\n",
    "    \"Vertebrate (other)\":\"lightblue\",\n",
    "    \"Plants\":\"green\",\n",
    "    \"Fungi\":\"palegreen\"\n",
    "           }\n",
    "\n",
    "umap.plot.points(taxid_2D_merged_min_max_scaled_embedding,\n",
    "                labels=taxonomy_info[['taxid', 'cats']].set_index('taxid').cats,\n",
    "                color_key=color_dict,\n",
    "                alpha=0.7,\n",
    "                background=\"ghostwhite\",\n",
    "                width=800,\n",
    "                height=800)\n",
    "patches = [mpatches.Patch(color=v, label=k) for k,v in color_dict.items()]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
